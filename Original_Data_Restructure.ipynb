{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web of Science Data Restucture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Web of Science data preprocessing\n",
    "In this step, raw Web of Science data were read into the RAM in a whole, identifying the contents by front codez like 'AB','TI' etc. We'll output the data in the form of .csv or Excel files.\n",
    "Attention: all seperated WOS files were previously combined in windows commandline, using \"dir /s/b\" and \"copy *.txt all.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Encoding in case of 'gbk' codec error\n",
    "Fileinput = open('D:/_Research/Project_Ecological_Development/Data_WoS_Original_Data/WC_Data_Combined/all.txt', encoding = u'utf-8')\n",
    "\n",
    "#Set Reocrds as a List and each reocord as a dict to save attributes\n",
    "Records = []\n",
    "record = {}\n",
    "CurrentTag = ''\n",
    "\n",
    "for line in Fileinput.readlines():\n",
    "    #Delete BOM Data in front, TM symbol in middle and \\n in the last\n",
    "    line = line.replace('\\xef\\xbb\\xbf','').replace('\\xe2\\x84\\xa2','').replace('\\n','')\n",
    "    #Extraction\n",
    "    if line[:2] != '  ' and len(line) > 0:\n",
    "        CurrentTag = line[:2]\n",
    "        if CurrentTag != 'ER':\n",
    "            record.update({CurrentTag:[line[3:]]})\n",
    "        elif line[:2] == 'ER':\n",
    "            Records.append(record)\n",
    "            record = {}\n",
    "    elif line[:2] == '  ':\n",
    "        record[CurrentTag].append(line[3:])\n",
    "Fileinput.close()\n",
    "\n",
    "for index,record in enumerate(Records):\n",
    "    for attr in record:\n",
    "        if isinstance(record[attr],list):\n",
    "            temp = ''\n",
    "            for line in record[attr]:\n",
    "                temp += line + '|'\n",
    "            Records[index][attr] = temp[:-1]\n",
    "    \n",
    "PRecords = pd.DataFrame.from_records(Records, index = range(len(Records)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Save processed data to disk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the restructured data into csv and xlsx files for future loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PRecords.to_csv('D:/_Research/Project_Ecological_Development/Data_Processing/Complete_Records_WOS_20171111.csv', encoding = u'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('D:/_Research/Project_Ecological_Development/Data_Processing/Complete_Records_WOS_20171111.xlsx')\n",
    "PRecords.to_excel(writer, 'Sheet1')\n",
    "writer.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
